{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjL8_Pgj7oqb",
        "outputId": "5a7af528-acb6-48a6-d9c1-ccc4c516807c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "root_dir = \"/content/gdrive/My Drive/\"\n",
        "base_dir = root_dir + 'Colab Notebooks/fastai_full'\n",
        "%reload_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDe8OpvU8V6g"
      },
      "source": [
        "import pandas as pd              \n",
        "import numpy as np         \n",
        "import os                  \n",
        "from random import shuffle \n",
        "import scipy\n",
        "import skimage\n",
        "from skimage.transform import resize\n",
        "import cv2\n",
        "import time\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FgVflQD8vO5"
      },
      "source": [
        "train_labels = pd.read_csv(base_dir+'/stage_2_train_labels.csv')\n",
        "df = train_labels.drop(['x','y','width','height'],axis='columns')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivLItep48lWH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "8261eb63-9948-42cf-cf55-5303e6c17838"
      },
      "source": [
        "def get_data(Dir, df=df):\n",
        "    X_train = []\n",
        "    y_train = []\n",
        "    X_test = []\n",
        "    y_test = []\n",
        "    i=0\n",
        "    for nextdir in os.listdir(Dir):\n",
        "        if nextdir.endswith('.jpg'):\n",
        "            i+=1\n",
        "            nextdir, label = nextdir, int(df[df.patientId==nextdir[:-4]].Target.array[0])\n",
        "            image = cv2.imread(Dir +'/'+nextdir, cv2.IMREAD_GRAYSCALE)\n",
        "            image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)\n",
        "            image = skimage.transform.resize(image, (299, 299, 3))\n",
        "                        #img_file = scipy.misc.imresize(arr=img_file, size=(299, 299, 3))\n",
        "            image= np.asarray(image)\n",
        "            if i%5==0:\n",
        "                X_test.append(image)\n",
        "                y_test.append(label)\n",
        "            else:\n",
        "                X_train.append(image)\n",
        "                y_train.append(label)\n",
        "        if i>3000:\n",
        "            break\n",
        "                    \n",
        "    X_train = np.asarray(X_train)\n",
        "    y_train = np.asarray(y_train)\n",
        "    X_test = np.asarray(X_test)\n",
        "    y_test = np.asarray(y_test)\n",
        "    return X_train, y_train, X_test, y_test"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6049afe75168>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jq3LKTMH-0DH"
      },
      "source": [
        "X_train, y_train, X_test, y_test = get_data(base_dir+'/grey_train')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyzPDtXDByv1",
        "outputId": "38113d30-463e-4077-aee8-c39ecabf7cb3"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300, 299, 299, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7t5LR3bJ_hs_"
      },
      "source": [
        "X_train = X_train.reshape(1201, 3, 299, 299)\n",
        "X_test = X_test.reshape(300, 3, 299, 299)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F72sjxV6_ncQ"
      },
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "y_train = to_categorical(y_train, 2)\n",
        "y_test = to_categorical(y_test, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYnJnRQQB5m8",
        "outputId": "88d7f3af-0fa1-449c-8cf1-6a608bd44671"
      },
      "source": [
        "from keras.callbacks import ReduceLROnPlateau , ModelCheckpoint , LearningRateScheduler\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, epsilon=0.0001, patience=1, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v80jIBXICAV8"
      },
      "source": [
        "filepath=\"transferlearning_weights.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AA9nK2IyCCVd"
      },
      "source": [
        "from keras.models import Sequential , Model\n",
        "from keras.layers import Dense , Activation\n",
        "from keras.layers import Dropout , GlobalAveragePooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.constraints import maxnorm\n",
        "from keras.optimizers import SGD , RMSprop , Adadelta , Adam\n",
        "from keras.layers import Conv2D , BatchNormalization\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNwIBPrdCFad",
        "outputId": "74a260b9-646c-4b1f-a998-25d253fe9b52"
      },
      "source": [
        "from keras.applications.inception_v3 import InceptionV3\n",
        "# create the base pre-trained model\n",
        "base_model = InceptionV3()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
            "96116736/96112376 [==============================] - 1s 0us/step\n",
            "96124928/96112376 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FJqgKX9CNgW"
      },
      "source": [
        "x = base_model.output\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "predictions = Dense(2, activation='sigmoid')(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8jbJyfuCPvN"
      },
      "source": [
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmYFrEPFCSH3"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', \n",
        "                  optimizer='adam', \n",
        "                  metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8qD5kdcCUyl"
      },
      "source": [
        "batch_size = 64\n",
        "epochs = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEzZqR0kCXV1",
        "outputId": "62259aa9-bd20-4ac5-adcd-b1720b38d645"
      },
      "source": [
        "def swish_activation(x):\n",
        "    return (K.sigmoid(x) * x)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(16, (3, 3), activation='relu', padding=\"same\", input_shape=(3,299,299)))\n",
        "model.add(Conv2D(16, (3, 3), padding=\"same\", activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding=\"same\", input_shape=(3,299,299)))\n",
        "model.add(Conv2D(32, (3, 3), padding=\"same\", activation='relu'))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding=\"same\"))\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\", activation='relu'))\n",
        "\n",
        "model.add(Conv2D(96, (3, 3), dilation_rate=(2, 2), activation='relu', padding=\"same\"))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), dilation_rate=(2, 2), activation='relu', padding=\"same\"))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(64, activation=swish_activation))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(2 , activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "                  optimizer=RMSprop(lr=0.00005),\n",
        "                  metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4tYV8JcCaG9",
        "outputId": "f5726bdb-5ce8-4a57-ca68-6db59a3de667"
      },
      "source": [
        "history = model.fit(X_train, y_train, validation_data = (X_test , y_test) ,callbacks=[lr_reduce,checkpoint] ,\n",
        "          epochs=epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 55s 991ms/step - loss: 0.6033 - accuracy: 0.8326 - val_loss: 0.4060 - val_accuracy: 0.8600\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.86000, saving model to transferlearning_weights.hdf5\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 35s 912ms/step - loss: 0.4231 - accuracy: 0.8569 - val_loss: 0.4046 - val_accuracy: 0.8600\n",
            "\n",
            "Epoch 00002: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.86000\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 35s 915ms/step - loss: 0.4375 - accuracy: 0.8412 - val_loss: 0.4029 - val_accuracy: 0.8600\n",
            "\n",
            "Epoch 00003: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-07.\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.86000\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 34s 891ms/step - loss: 0.3956 - accuracy: 0.8662 - val_loss: 0.4029 - val_accuracy: 0.8600\n",
            "\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 4.999999987376214e-08.\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.86000\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 34s 900ms/step - loss: 0.4043 - accuracy: 0.8618 - val_loss: 0.4029 - val_accuracy: 0.8600\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 5.000000058430488e-09.\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.86000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}